{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNSksiyi0iZWHFjvgHfPyLm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pooja-Informatics/symmetrical-orchid/blob/main/all_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "All data files"
      ],
      "metadata": {
        "id": "q9n2jsWSjHbC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Mounting drive folders to collab**"
      ],
      "metadata": {
        "id": "uKmcvNK2Kkk2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TqnCG6iUZLnd",
        "outputId": "baa649ac-23b6-47ec-d8bd-357adf4a4da1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "filePath ='/content/drive/MyDrive/Data_training/train_data_all_files/clean_trainset_wav'\n",
        "filePath ='/content/drive/MyDrive/Data_training/train_data_all_files/noisy_trainset_wav'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Training**"
      ],
      "metadata": {
        "id": "XW6Bzvn4AtJW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import librosa\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "noisy_folder = '/content/drive/MyDrive/Data_training/train_data_all_files/noisy_trainset_wav'\n",
        "clean_folder = '/content/drive/MyDrive/Data_training/train_data_all_files/clean_trainset_wav'\n",
        "frame_length = 100  # Length of each frame in samples\n",
        "batch_size = 32\n",
        "\n",
        "# Function to load audio from file\n",
        "def load_audio(file_path):\n",
        "    audio, _ = tf.audio.decode_wav(tf.io.read_file(file_path))\n",
        "    audio = tf.squeeze(audio, axis=-1)\n",
        "    return audio.numpy()\n",
        "\n",
        "# Function to convert audio into frames\n",
        "def convert_audio_to_frames(audio, frame_length):\n",
        "    num_frames = len(audio) // frame_length\n",
        "    frames = np.array_split(audio[:num_frames * frame_length], num_frames)\n",
        "    return frames\n",
        "\n",
        "# Function to create the data generator\n",
        "def create_data_generator(noisy_folder, clean_folder, frame_length, batch_size):\n",
        "    noisy_files = os.listdir(noisy_folder)\n",
        "    clean_files = os.listdir(clean_folder)\n",
        "    assert len(noisy_files) == len(clean_files)\n",
        "\n",
        "    num_examples = len(noisy_files)\n",
        "    num_batches = num_examples // batch_size\n",
        "\n",
        "    while True:\n",
        "        np.random.shuffle(noisy_files)\n",
        "        np.random.shuffle(clean_files)\n",
        "\n",
        "        for i in range(num_batches):\n",
        "            batch_noisy = []\n",
        "            batch_clean = []\n",
        "\n",
        "            for j in range(i * batch_size, (i + 1) * batch_size):\n",
        "                noisy_path = os.path.join(noisy_folder, noisy_files[j])\n",
        "                clean_path = os.path.join(clean_folder, clean_files[j])\n",
        "\n",
        "                noisy_audio = load_audio(noisy_path)\n",
        "                clean_audio = load_audio(clean_path)\n",
        "\n",
        "                # Adjust frame splitting to match the number of frames in both noisy and clean audio\n",
        "                num_frames = min(len(noisy_audio), len(clean_audio)) // frame_length\n",
        "                noisy_frames = convert_audio_to_frames(noisy_audio, frame_length)[:num_frames]\n",
        "                clean_frames = convert_audio_to_frames(clean_audio, frame_length)[:num_frames]\n",
        "\n",
        "                batch_noisy.extend(noisy_frames)\n",
        "                batch_clean.extend(clean_frames)\n",
        "\n",
        "            batch_noisy = np.array(batch_noisy)\n",
        "            batch_clean = np.array(batch_clean)\n",
        "\n",
        "            yield batch_noisy, batch_clean\n",
        "\n",
        "# Define the Wave-U-Net architecture\n",
        "def wave_u_net(input_shape):\n",
        "    inputs = Input(shape=input_shape)\n",
        "\n",
        "    # Encoder\n",
        "    conv1 = Conv1D(filters=32, kernel_size=3, padding='same', activation='relu')(inputs)\n",
        "    pool1 = MaxPooling1D(pool_size=2)(conv1)\n",
        "\n",
        "    conv2 = Conv1D(filters=64, kernel_size=3, padding='same', activation='relu')(pool1)\n",
        "    pool2 = MaxPooling1D(pool_size=2)(conv2)\n",
        "\n",
        "    conv3 = Conv1D(filters=128, kernel_size=3, padding='same', activation='relu')(pool2)\n",
        "    pool3 = MaxPooling1D(pool_size=2)(conv3)\n",
        "\n",
        "    # Decoder\n",
        "    up4 = UpSampling1D(size=2)(pool3)\n",
        "    up4_padded = ZeroPadding1D(padding=(1, 0))(up4)  # Padding added here\n",
        "    concat4 = Concatenate()([conv3, up4_padded])\n",
        "    conv4 = Conv1D(filters=128, kernel_size=3, padding='same', activation='relu')(concat4)\n",
        "\n",
        "    up5 = UpSampling1D(size=2)(conv4)\n",
        "    up5_padded = ZeroPadding1D(padding=(1, 0))(up5)  # Padding added here\n",
        "    concat5 = Concatenate()([conv2, up5])\n",
        "    conv5 = Conv1D(filters=64, kernel_size=3, padding='same', activation='relu')(concat5)\n",
        "\n",
        "    up6 = UpSampling1D(size=2)(conv5)\n",
        "    up6_padded = ZeroPadding1D(padding=(1, 0))(up6)  # Padding added here\n",
        "    concat6 = Concatenate()([conv1, up6])\n",
        "    conv6 = Conv1D(filters=32, kernel_size=3, padding='same', activation='relu')(concat6)\n",
        "\n",
        "    # Output\n",
        "    output = Conv1D(filters=1, kernel_size=3, padding='same')(conv6)\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=output)\n",
        "    return model\n",
        "\n",
        "# Define the input shape for the Wave-U-Net model\n",
        "input_shape = (frame_length, 1)\n",
        "\n",
        "# Create the Wave-U-Net model\n",
        "model = wave_u_net(input_shape)\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "# Create the data generator\n",
        "data_generator = create_data_generator(noisy_folder, clean_folder, frame_length, batch_size)\n",
        "\n",
        "# Train the model using the data generator\n",
        "model.fit(data_generator, steps_per_epoch=10, epochs=1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ReSgnUXZa-i",
        "outputId": "964240c0-e7b0-48c1-92d7-d317c6c4d351"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10/10 [==============================] - 229s 23s/step - loss: 0.0040\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fcb7c301b70>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Testing**\n"
      ],
      "metadata": {
        "id": "7m2jYfi346hz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Audio folder converted to list of arrays\n"
      ],
      "metadata": {
        "id": "iUEK4-zQGVEN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import librosa\n",
        "\n",
        "def convert_folder_to_arrays(folder_path):\n",
        "    audio_arrays = []\n",
        "\n",
        "    # Iterate over the files in the folder\n",
        "    for filename in os.listdir(folder_path):\n",
        "        file_path = os.path.join(folder_path, filename)\n",
        "\n",
        "        # Load the audio file using librosa\n",
        "        audio, _ = librosa.load(file_path, sr=None)\n",
        "\n",
        "        # Append the audio array to the list\n",
        "        audio_arrays.append(audio)\n",
        "\n",
        "    return audio_arrays\n",
        "\n",
        "def convert_arrays_to_frames(audio_arrays, frame_length):\n",
        "    list_frames = []\n",
        "\n",
        "    # Iterate over the audio arrays\n",
        "    for audio in audio_arrays:\n",
        "        num_frames = len(audio) // frame_length\n",
        "\n",
        "        audio_frames = np.array_split(audio[:num_frames * frame_length], num_frames)\n",
        "        list_frames.extend(audio_frames)\n",
        "\n",
        "    return list_frames\n",
        "\n",
        "# Define the folder path\n",
        "folder_path = '/content/drive/MyDrive/Data_training/train_data_all_files/noisy_testset_wav'\n",
        "\n",
        "# Converted the folder of audio files into a list of arrays\n",
        "audio_arrays = convert_folder_to_arrays(folder_path)\n",
        "\n",
        "# Defineed the frame length\n",
        "frame_length =100\n",
        "#16000\n",
        "\n",
        "# Converted the list of arrays into a list of frames\n",
        "list_frames = convert_arrays_to_frames(audio_arrays, frame_length)"
      ],
      "metadata": {
        "id": "yBHtyfZubOJ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To get Predicted frames from model"
      ],
      "metadata": {
        "id": "2aCtCzSQGN89"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Converted the list of frames to a NumPy array\n",
        "frames_array = np.array(list_frames)\n",
        "\n",
        "# Reshaped the frames array\n",
        "reshaped_frames = frames_array.reshape((-1, frame_length, 1))\n",
        "\n",
        "# Predicted using the model\n",
        "predictions = model.predict(reshaped_frames)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0jhgOS7nFltH",
        "outputId": "3fbd0e7f-2dfc-45fd-816c-f7071d791692"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4192/4192 [==============================] - 65s 15ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function to convert audio folder into list of arrays of audios"
      ],
      "metadata": {
        "id": "dMrS_a0KuHYh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import soundfile as sf\n",
        "\n",
        "folder_path = '/content/drive/MyDrive/Data_training/train_data_all_files/noisy_testset_wav'\n",
        "# Replace with the path to your folder\n",
        "\n",
        "audio_arrays = []  # List to store the audio arrays\n",
        "audio_filenames = []  # List to store the audio filenames\n",
        "\n",
        "# Iterate over the files in the folder\n",
        "for filename in os.listdir(folder_path):\n",
        "    file_path = os.path.join(folder_path, filename)\n",
        "\n",
        "    # Read the audio file and store as array\n",
        "    audio, _ = sf.read(file_path)\n",
        "\n",
        "    # Append the audio array to the list\n",
        "    audio_arrays.append(audio)\n",
        "\n",
        "    # Append the filename to the list\n",
        "    audio_filenames.append(filename)\n",
        "\n",
        "# Print the audio files converted to arrays along with their filenames\n",
        "for i, audio in enumerate(audio_arrays):\n",
        "    filename = audio_filenames[i]\n",
        "    print(f\"Audio file {i+1}: {filename}\")\n",
        "    print(audio)\n",
        "    print()  # Add an empty line between audio arrays\n"
      ],
      "metadata": {
        "id": "j0kvfYetieue"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "1.   Function to convert list of arrays of audios into list of frames\n",
        "2.   Function to find total number of frames in each audio array\n",
        "1.   Function to store number of frames in a array\n",
        "  \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "psQZkuK1uYxp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "audio_arrays  # list of audio arrays\n",
        "\n",
        "frame_length =100\n",
        "\n",
        "# List to store the frames for each audio array\n",
        "audio_frames = []\n",
        "\n",
        "# Array to store the number of frames for each audio array\n",
        "num_frames_array = []\n",
        "\n",
        "# Iterate over the audio arrays\n",
        "for audio in audio_arrays:\n",
        "    # Calculate the number of frames for each audio array\n",
        "    num_frames = len(audio) // frame_length\n",
        "    num_frames_array.append(num_frames)\n",
        "\n",
        "    # Split the audio array into frames\n",
        "    frames = [audio[i*frame_length : (i+1)*frame_length] for i in range(num_frames)]\n",
        "\n",
        "    # Add the frames to the list\n",
        "    audio_frames.append(frames)\n",
        "\n",
        "    # Print the total number of frames for each audio array\n",
        "    print(f\"Total number of frames in audio array: {num_frames}\")\n",
        "\n",
        "# we can Print the list of frames for each audio array\n",
        "\n"
      ],
      "metadata": {
        "id": "Kjo1QA2Tg0lG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Storing predicted frames from model into final respective frames with frame numbers"
      ],
      "metadata": {
        "id": "bcWXiU_pPgN0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def reshape_frames(frames_list, num_frames_array):\n",
        "    reshaped_frames = []\n",
        "    start_idx = 0\n",
        "    for num_frames in num_frames_array:\n",
        "        end_idx = start_idx + num_frames\n",
        "        audio_frames = frames_list[start_idx:end_idx]\n",
        "        reshaped_frames.append(audio_frames)\n",
        "        start_idx = end_idx\n",
        "    return reshaped_frames\n",
        "\n",
        "# Example usage\n",
        "frames_list =predictions\n",
        "num_frames_array = np.array(num_frames_array)\n",
        "reshaped_frames = reshape_frames(frames_list, num_frames_array)\n",
        "\n",
        "# Print the reshaped frames\n",
        "#for i, frames in enumerate(reshaped_frames):\n",
        "   #print(f\"Frames for audio {i+1}:\")\n",
        "    #for frame in frames:\n",
        "       #print(frame)\n",
        "    #print(\"---\")\n"
      ],
      "metadata": {
        "id": "odDBXEPyPBmU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Storing audio files into drive folder**"
      ],
      "metadata": {
        "id": "qMepCmMx7A1c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import soundfile as sf\n",
        "import numpy as np\n",
        "\n",
        "def convert_frames_to_audio(num_frames_array, audio_frames, output_folder, sampling_rate, file_names):\n",
        "\n",
        "    for i, frames in enumerate(audio_frames):\n",
        "        num_frames = num_frames_array[i]\n",
        "        frame_length = len(frames[0])  # Assuming all frames have the same length\n",
        "\n",
        "        # Concatenate the frames to reconstruct the audio array\n",
        "        audio = np.concatenate(frames)\n",
        "\n",
        "        # Calculate the total length of the audio in samples\n",
        "        audio_length = num_frames * frame_length\n",
        "\n",
        "        # Get the corresponding file name\n",
        "        output_filename = file_names[i]\n",
        "\n",
        "        # Set the output file path\n",
        "        output_path = os.path.join(output_folder, output_filename)\n",
        "\n",
        "        # Save the audio file with the correct sampling rate and subtype\n",
        "        sf.write(output_path, audio[:audio_length], sampling_rate, 'PCM_16')\n",
        "\n",
        "        print(f\"Saved audio file {output_filename} to {output_folder}\")\n",
        "\n",
        "\n",
        "# Example usage\n",
        "num_frames_array =num_frames_array   # Example array of number of frames\n",
        "audio_frames = reshaped_frames  # Example list of frames\n",
        "output_folder = '/content/drive/MyDrive/Data_training/train_data_all_files/output_wav'  # Output folder path\n",
        "sampling_rate = 44100\n",
        "file_names =  audio_filenames# Array of file names\n",
        "\n",
        "convert_frames_to_audio(num_frames_array, audio_frames, output_folder, sampling_rate, file_names)"
      ],
      "metadata": {
        "id": "UJG6Xvm4jY0F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluation**"
      ],
      "metadata": {
        "id": "n6VPIpc7GiUV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import soundfile as sf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "import csv\n",
        "\n",
        "# Variables\n",
        "predDataPath =  'output_wav/'\n",
        "#'Enh_clean/' # Predicted data file directory\n",
        "cleanDataPath = 'clean_testset_wav/' # Reference/clean data file directory\n",
        "\n",
        "# Mounting GoogleDrive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "filePath =  '/content/drive/MyDrive/Data_training/train_data_all_files/'\n",
        "# SNR criteria\n",
        "def signal_noise_ratio(signal, noise):\n",
        "  if len(signal) != len(noise): # For different lengths signals\n",
        "    if len(signal) > len(noise):\n",
        "      signal = signal[0:len(noise)]\n",
        "    else:\n",
        "      noise = noise[0:len(signal)]\n",
        "  if len(signal) == len(noise): # For equal length signals\n",
        "    tmp = signal / len(signal)\n",
        "    se = np.sum(np.multiply(tmp, tmp))\n",
        "    tmp = noise / len(noise)\n",
        "    ne = np.sum(np.multiply(tmp, tmp))\n",
        "    snr = 10 * np.log10(se/ne)\n",
        "  else:\n",
        "    snr = np.nan\n",
        "  return snr\n",
        "\n",
        "\n",
        "# Reading directories\n",
        "def dir_file_reading(drivePath, dataFolder):\n",
        "  # drivePath - the main working directory\n",
        "  # dataFolder - data folder\n",
        "  fullDataPath = drivePath + dataFolder\n",
        "  fileList = os.listdir(fullDataPath)\n",
        "  data = []\n",
        "  files = []\n",
        "  for file in fileList:\n",
        "    audio, fs = sf.read(fullDataPath + file) # Nuskaitom duomenis\n",
        "    data.append(audio)\n",
        "    files.append(file)\n",
        "  return data, files\n",
        "\n",
        "# Reading the directories\n",
        "predData, predFiles = dir_file_reading(filePath, predDataPath)\n",
        "cleanData, cleanFiles = dir_file_reading(filePath, cleanDataPath)\n",
        "# Reference/clean and predicted signal differences are evaluated\n",
        "\n",
        "print('Saving result file...')\n",
        "# Creation and saving file\n",
        "now = datetime.now()\n",
        "fileName = now.strftime(\"Results_%Y-%m-%d_%H:%M.csv\")\n",
        "data = ['File', 'SNR']\n",
        "\n",
        "for i in range(len(predFiles)):\n",
        "  file = predFiles[i]\n",
        "  print(file)\n",
        "  print(cleanFiles)\n",
        "  print('--------------')\n",
        "  if file in cleanFiles:\n",
        "    for j in range(len(cleanFiles)):\n",
        "      if file == cleanFiles[j]:\n",
        "        if len(cleanData[j]) > len(predData[i]):\n",
        "          cleanData[j] = cleanData[j][0:len(predData[i])]\n",
        "        else:\n",
        "          predData[i] = predData[i][0:len(cleanData[j])]\n",
        "        noise = np.subtract(predData[i], cleanData[j])\n",
        "        snr = signal_noise_ratio(cleanData[j], noise)\n",
        "        print(snr)\n",
        "        data = np.vstack([data, [file, snr]])\n",
        "        break\n",
        "\n",
        "with open(filePath + fileName, 'w') as csvFile:\n",
        "  csvWriter = csv.writer(csvFile)\n",
        "  csvWriter.writerows(data) # Data\n"
      ],
      "metadata": {
        "id": "o_sFlzIFO7N8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}